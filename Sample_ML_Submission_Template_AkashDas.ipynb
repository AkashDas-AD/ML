{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkashDas-AD/ML/blob/main/Sample_ML_Submission_Template_AkashDas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Retail Sales Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression - Rossmann Retail Sales Prediction\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -** https://github.com/AkashDas-AD/ML\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied.\n",
        "You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishmen"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import missingno as msno\n",
        "import matplotlib\n",
        "import matplotlib.pylab as pylab\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "matplotlib.style.use('ggplot')\n",
        "sns.set_style('white')\n",
        "pylab.rcParams['figure.figsize'] = 8,6\n",
        "\n",
        "import math\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.linear_model import LassoLars\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "rossmann_df = pd.read_excel('Rossmann Stores Data.xlsx')\n",
        "store_df = pd.read_csv('store.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "rossmann_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.head()"
      ],
      "metadata": {
        "id": "6T0ue3ATGWGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rossmann_df.shape , store_df.shape"
      ],
      "metadata": {
        "id": "PSugTj7wGfNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "rossmann_df.info() , store_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "\n",
        "duplicate_data=rossmann_df.duplicated().sum()\n",
        "duplicate_data1 = store_df.duplicated().sum()\n",
        "duplicate_data,duplicate_data1"
      ],
      "metadata": {
        "id": "69NhuguyMesN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "\n",
        "rossmann_df.isnull().sum(), store_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(store_df.isnull(), cmap='viridis', cbar=False, yticklabels=False)\n",
        "plt.title('Visualization of Null Values in store_df')\n",
        "plt.xlabel('Columns')\n",
        "plt.ylabel('Rows')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "rossmaann_df comprises of 1017209 rows and  9 columns and store_df comprises of 1115 rows and 10 columns.\n",
        "\n",
        "Missing Values : Notable missing values in the CompetitionOpenSinceMonth,\n",
        "CompetitionOpenSinceYear,Promo2SinceWeek,Promo2SinceYear,PromoInterval, CompetitionDistance  \n",
        "\n",
        "Duplicate Values : There are no duplicate values in the dataset."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "\n",
        "rossmann_df.columns , store_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "\n",
        "rossmann_df.describe() , store_df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data fields\n",
        "Most of the fields are self-explanatory. The following are descriptions for those that aren't.\n",
        "\n",
        "Id - an Id that represents a (Store, Date) duple within the test set\n",
        "\n",
        "Store - a unique Id for each store\n",
        "\n",
        "Sales - the turnover for any given day (this is what you are predicting)\n",
        "\n",
        "Customers - the number of customers on a given day\n",
        "\n",
        "Open - an indicator for whether the store was open: 0 = closed, 1 = open\n",
        "\n",
        "StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
        "\n",
        "SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools\n",
        "\n",
        "StoreType - differentiates between 4 different store models: a, b, c, d\n",
        "\n",
        "Assortment - describes an assortment level: a = basic, b = extra, c = extended\n",
        "\n",
        "CompetitionDistance - distance in meters to the nearest competitor store\n",
        "\n",
        "CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\n",
        "\n",
        "Promo - indicates whether a store is running a promo on that day\n",
        "\n",
        "Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
        "\n",
        "Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\n",
        "\n",
        "PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "def check_unique_values(df1, df2):\n",
        "    print(\"Unique Values in DataFrame 1:\")\n",
        "    for col in df1.columns.tolist():\n",
        "        print(\"No. of unique values in \", col, \" = \", df1[col].nunique())\n",
        "\n",
        "    print(\"\\nUnique Values in DataFrame 2:\")\n",
        "    for col in df2.columns.tolist():\n",
        "        print(\"No. of unique values in \", col, \" = \", df2[col].nunique())\n",
        "\n",
        "# Call the function with your two DataFrames\n",
        "check_unique_values(rossmann_df,store_df )"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA and Visualization On Rossman Dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "# extract year, month, day and week of year from \"Date\"\n",
        "\n",
        "rossmann_df['Year'] = rossmann_df['Date'].apply(lambda x: x.year)\n",
        "rossmann_df['Month'] = rossmann_df['Date'].apply(lambda x: x.month)\n",
        "rossmann_df['Day'] = rossmann_df['Date'].apply(lambda x: x.day)\n",
        "rossmann_df['WeekOfYear'] = rossmann_df['Date'].apply(lambda x: x.weekofyear)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rossmann_df.sort_values(by=['Date','Store'],inplace=True,ascending=[False,True])\n",
        "rossmann_df.head(2)"
      ],
      "metadata": {
        "id": "G3mshOJfFFzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Heatmap of the Rossman Dataset\n",
        "numeric_columns = rossmann_df.select_dtypes(include=['int64', 'float64'])\n",
        "correlation_map = rossmann_df[numeric_columns.columns].corr()\n",
        "obj = np.array(correlation_map)\n",
        "obj[np.tril_indices_from(obj)] = False\n",
        "fig,ax= plt.subplots()\n",
        "fig.set_size_inches(9,9)\n",
        "sns.heatmap(correlation_map, mask=obj,vmax=.7, square=True,annot=True)"
      ],
      "metadata": {
        "id": "l2KHqbsfLDe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check on which date the stores are mainly open\n",
        "\n",
        "sns.countplot(x='DayOfWeek',hue='Open',data=rossmann_df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UMbe2avSNA_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Impact of promo on sales\n",
        "Promo_sales = pd.DataFrame(rossmann_df.groupby('Promo').agg({'Sales':'mean'}))\n",
        "sns.barplot(x=Promo_sales.index, y = Promo_sales['Sales'])"
      ],
      "metadata": {
        "id": "wAMxGCSPNuEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Monthly sales\n",
        "sns.catplot(x=\"Month\", y=\"Sales\", data=rossmann_df, kind=\"point\", aspect=2, height=6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-92j3enHOK_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Value Counts of SchoolHoliday Column\n",
        "rossmann_df.SchoolHoliday.value_counts()"
      ],
      "metadata": {
        "id": "lMZhoTKWTER7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if school holiday has affected the sales or not.\n",
        "\n",
        "labels = 'Not-Affected' , 'Affected'\n",
        "sizes = rossmann_df.SchoolHoliday.value_counts()\n",
        "colors = ['gold', 'silver']\n",
        "explode = (0.1, 0.0)\n",
        "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
        "        autopct='%1.1f%%', shadow=True, startangle=180)\n",
        "plt.axis('equal')\n",
        "plt.title(\"Effect of sales during school holiday\",fontsize=10)\n",
        "plt.plot()\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(6,6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3sBxMR5PVdCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforming Variable StateHoliday\n",
        "\n",
        "rossmann_df[\"StateHoliday\"] = rossmann_df[\"StateHoliday\"].map({0: 0, \"0\": 0, \"a\": 1, \"b\": 1, \"c\": 1})\n",
        "rossmann_df.StateHoliday.value_counts()"
      ],
      "metadata": {
        "id": "2k6KV8Rsa6ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if state holidays has affected the sales or not.\n",
        "labels = 'Not-Affected' , 'Affected'\n",
        "sizes = rossmann_df.StateHoliday.value_counts()\n",
        "colors = ['orange','green']\n",
        "explode = (0.1, 0.0)\n",
        "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
        "        autopct='%1.1f%%', shadow=True, startangle=180)\n",
        "plt.axis('equal')\n",
        "plt.title(\"Effect of sales during state holiday\",fontsize=10)\n",
        "plt.plot()\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(6,6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Se2zemz4cZ7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sales doesnot affect during state holiday so dropping State Holiday column\n",
        "\n",
        "rossmann_df.drop('StateHoliday',inplace=True,axis=1)"
      ],
      "metadata": {
        "id": "pg-8cGNOgS0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#linear relation between sales and customers\n",
        "sns.lmplot(x= 'Sales' , y ='Customers',data=rossmann_df, palette='seismic', height=5,aspect=1, line_kws={'color':'blue'})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r5XhuwenicXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA and visualizing the Store Dataset"
      ],
      "metadata": {
        "id": "1hJuxZd2kdbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove features with high percentages of missing values\n",
        "# we can see that some features have a high percentage of missing values and they won't be accurate as indicators,\n",
        "#so we will remove features with more than 30% missing values.\n",
        "\n",
        "store_df = store_df.drop(['CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear','Promo2SinceWeek',\n",
        "                     'Promo2SinceYear', 'PromoInterval'], axis=1)"
      ],
      "metadata": {
        "id": "QdPz9CS3mYEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace missing values in features with low percentages of missing values\n",
        "\n",
        "# CompetitionDistance is distance in meters to the nearest competitor store\n",
        "# let's first have a look at its distribution\n",
        "\n",
        "sns.distplot(store_df.CompetitionDistance.dropna())\n",
        "plt.title(\"Distributin of Store Competition Distance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D84cziqIm0Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The distribution is right skewed, so we'll replace missing values with the median.\n",
        "\n",
        "store_df.CompetitionDistance.fillna(store_df.CompetitionDistance.median(), inplace=True)"
      ],
      "metadata": {
        "id": "tu1tpnJRnNtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution Of Different Store Types\n",
        "\n",
        "labels = 'a' , 'b' , 'c' , 'd'\n",
        "sizes = store_df.StoreType.value_counts()\n",
        "colors = ['orange', 'green' , 'red' , 'pink']\n",
        "explode = (0.1, 0.0 , 0.15 , 0.0)\n",
        "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
        "        autopct='%1.1f%%', shadow=True, startangle=180)\n",
        "plt.axis('equal')\n",
        "plt.title(\"Distribution of different StoreTypes\")\n",
        "plt.plot()\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(6,6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TzTrZ-u6j2OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pairplot for Store Dataset\n",
        "\n",
        "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
        "pp=sns.pairplot(store_df,hue='StoreType')\n",
        "pp.fig.set_size_inches(10,10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K_iRoJpGl632"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merging Two Datasets\n",
        "\n",
        "df = pd.merge(rossmann_df, store_df, on='Store', how='left')"
      ],
      "metadata": {
        "id": "CbxDf9XlptDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "ssOp9IHfp4E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "hroNSMkFrp9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting heatmap on the merged dataset\n",
        "numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "plt.figure(figsize=(20,12))\n",
        "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap of Numeric Columns\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "33q-MVokp9OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Avg_Customer_Sales\"] = df.Sales/df.Customers"
      ],
      "metadata": {
        "id": "SOfZeornvIUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(2, 3, figsize = (20,10))\n",
        "\n",
        "store_df.groupby(\"StoreType\")[\"Store\"].count().plot(kind = \"bar\", ax = ax[0, 0], title = \"Total StoreTypes in the Dataset\")\n",
        "df.groupby(\"StoreType\")[\"Sales\"].sum().plot(kind = \"bar\", ax = ax[0,1], title = \"Total Sales of the StoreTypes\")\n",
        "df.groupby(\"StoreType\")[\"Customers\"].sum().plot(kind = \"bar\", ax = ax[0,2], title = \"Total nr Customers of the StoreTypes\")\n",
        "df.groupby(\"StoreType\")[\"Sales\"].mean().plot(kind = \"bar\", ax = ax[1,0], title = \"Average Sales of StoreTypes\")\n",
        "df.groupby(\"StoreType\")[\"Avg_Customer_Sales\"].mean().plot(kind = \"bar\", ax = ax[1,1], title = \"Average Spending per Customer\")\n",
        "df.groupby(\"StoreType\")[\"Customers\"].mean().plot(kind = \"bar\", ax = ax[1,2], title = \"Average Customers per StoreType\")\n",
        "\n",
        "plt.subplots_adjust(hspace = 0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0-b7eUXlva0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the graphs, the StoreType A has the most stores, sales and customers. However the StoreType D has the best averages spendings per customers. StoreType B, with only 17 stores has the most average customers."
      ],
      "metadata": {
        "id": "U6HufFf0vkoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparison of sales when promo is on\n",
        "sns.catplot(data=df, x=\"Month\", y=\"Sales\",\n",
        "            col='Promo',\n",
        "            hue='Promo2',\n",
        "            row=\"Year\",\n",
        "            kind=\"point\",\n",
        "            aspect=1.5,\n",
        "            height=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C2OseziAx6F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sales for every day of a week\n",
        "\n",
        "sns.catplot(data=df, x=\"DayOfWeek\", y=\"Sales\", hue=\"Promo\", kind=\"point\", aspect=1.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AhpU1Ey-NOLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sales for yearly basis\n",
        "\n",
        "sns.catplot(data=df, x=\"Month\", y=\"Sales\", col=\"Year\", hue=\"StoreType\", kind=\"point\", aspect=1.5, height=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OPFotQrPPeDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "BvtYg61kRvIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removed becouse box plot showed to many outliers\n",
        "df.drop(['Avg_Customer_Sales','CompetitionDistance'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "7rbyckIPSQTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking outliers in sales\n",
        "sns.boxplot(rossmann_df['Sales'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x5oW695nSkFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deceting outliers with z-score method.\n",
        "\n",
        "# Calculate the Z-scores for the Sales column\n",
        "df['Sales_zscore'] = stats.zscore(df['Sales'])\n",
        "\n",
        "# Identify outliers based on Z-scores (|Z| > 3)\n",
        "outliers = df[df['Sales_zscore'].abs() > 3]\n",
        "\n",
        "# Display the outliers\n",
        "outliers.shape"
      ],
      "metadata": {
        "id": "Z5hUho3ITltD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the ouliers are less than 1% of the data set we are removing all the outliers.\n",
        "\n",
        "df = df[df['Sales_zscore'].abs() <= 3]\n",
        "\n",
        "# Drop the temporary Z-score column if not needed anymore\n",
        "df = df.drop(columns=['Sales_zscore'])"
      ],
      "metadata": {
        "id": "UZNg3KsSS2vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "UmVgm2bdbXsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion of the analysis:**\n",
        "Sales are highly correlated to number of Customers.\n",
        "\n",
        "The most selling and crowded store type is A.\n",
        "\n",
        "StoreType B has the lowest Average Sales per Customer. So i think customers visit this type only for small things.\n",
        "\n",
        "StoreTybe D had the highest buyer cart.\n",
        "\n",
        "Promo runs only in weekdays.\n",
        "\n",
        "For all stores, Promotion leads to increase in Sales and Customers both.\n",
        "\n",
        "More stores are opened during School holidays than State holidays.\n",
        "\n",
        "The stores which are opened during School Holiday have more sales than normal days.\n",
        "\n",
        "Sales are increased during Chirstmas week, this might be due to the fact that people buy more beauty products during a Christmas celebration.\n",
        "\n",
        "Promo2 doesnt seems to be correlated to any significant change in the sales amount.\n",
        "\n"
      ],
      "metadata": {
        "id": "34TnxFuxbxMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Drop Subsets Of Data Where Might Cause Bias***"
      ],
      "metadata": {
        "id": "mry19OLTcUBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# where stores are closed, they won't generate sales, so we will remove that part of the dataset\n",
        "df = df[df.Open != 0]"
      ],
      "metadata": {
        "id": "fx_3geaMcTAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open isn't a variable anymore, so we'll drop it too\n",
        "df = df.drop('Open', axis=1)"
      ],
      "metadata": {
        "id": "CXYoHyMVcMqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if there's any opened store with zero sales\n",
        "df[df.Sales == 0]['Store'].sum()"
      ],
      "metadata": {
        "id": "El_Diz03cmdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see the percentage of open stored with zero sales\n",
        "df[df.Sales == 0]['Sales'].sum()/df.Sales.sum()"
      ],
      "metadata": {
        "id": "lQ-uDXxMcrsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove this part of data to avoid bias\n",
        "df = df[df.Sales != 0]"
      ],
      "metadata": {
        "id": "AlzAyn55ct8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new=df.copy()"
      ],
      "metadata": {
        "id": "dnyqvwjPczUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.get_dummies(df_new,columns=['StoreType','Assortment'])"
      ],
      "metadata": {
        "id": "ip7dpC6uc3qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot for sales in terms of days ofthe week\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.barplot(x='DayOfWeek', y='Sales' ,data=df_new);"
      ],
      "metadata": {
        "id": "FsmfD-Qvc9Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From plot it can be sen that most of the sales have been on 1st and last day of week"
      ],
      "metadata": {
        "id": "kWWRyPhcdFwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting Features and Target Variables\n",
        "\n",
        "X = df_new.drop(['Sales','Store','Date','Year'] , axis = 1)\n",
        "y= df_new.Sales"
      ],
      "metadata": {
        "id": "sjVWWz8sdMS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape,y.shape"
      ],
      "metadata": {
        "id": "af7vRBoedgQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting Dataset Into Training Set and Test Set\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "75j8mBdxdd7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns=X_train.columns"
      ],
      "metadata": {
        "id": "rjS_se4Od4GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defined function for evaluation matrix.\n",
        "\n",
        "def mape(x, y):\n",
        "    return np.mean(np.abs((x - y) / x)) * 100\n",
        "\n",
        "def rmspe(y_true, y_pred):\n",
        "\n",
        "    loss = np.sqrt(np.mean(np.square(((y_true - y_pred) / y_pred)), axis=0))\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "yNax0z-Zerao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 - Linear Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "#Build linear regression model\n",
        "lin_model = LinearRegression()\n",
        "\n",
        "#Train model on training dataset\n",
        "lin_model.fit(X_train,y_train )\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict using model\n",
        "\n",
        "yd_predicted = lin_model.predict(X_train)\n",
        "\n",
        "#Calculate RMSE and MAPE\n",
        "\n",
        "print(\"The model performance for training dataset:\\n\")\n",
        "print(\"RMSPE :\",rmspe(y_train, yd_predicted))\n",
        "print(\"MAPE :\",mape(y_train, yd_predicted))"
      ],
      "metadata": {
        "id": "tx8cYAujfrVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict target on test data using model\n",
        "\n",
        "yd_test_predicted = lin_model.predict(X_test)\n",
        "\n",
        "#Calculate RMSE and MAPE\n",
        "\n",
        "print(\"The model performance for test dataset:\\n\")\n",
        "print(\"RMSPE :\",rmspe(y_test, yd_test_predicted))\n",
        "print(\"MAPE :\",mape(y_test, yd_test_predicted))"
      ],
      "metadata": {
        "id": "4cRj438JjMpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the regressor score.\n",
        "train_score_1=lin_model.score(X_train,y_train)\n",
        "test_score_1=lin_model.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "zTPn5f3ghR1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score_1,test_score_1"
      ],
      "metadata": {
        "id": "WGNPFmuYj6Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#storing 100 observations for analysis\n",
        "simple_lr_pred = yd_test_predicted[:100]\n",
        "simple_lr_real = y_test[:100]\n",
        "dataset_lr = pd.DataFrame({'Real':simple_lr_real,'PredictedLR':simple_lr_pred}) #storing these values into dataframe\n",
        "#storing absolute diffrences between actual sales price and predicted\n",
        "dataset_lr['diff']=(dataset_lr['Real']-dataset_lr['PredictedLR']).abs()\n",
        "#visualising our predictions\n",
        "sns.lmplot(x='Real', y='PredictedLR', data=dataset_lr, line_kws={'color': 'black'});"
      ],
      "metadata": {
        "id": "NE1Xl_a8j_f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 - Random Forest"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Not able to execute because it crashes whhile executing\n",
        "# rfr=RandomForestRegressor(n_jobs=-1)\n",
        "\n",
        "# params = {\n",
        "#          'n_estimators':[40,50,60,70,80,90],\n",
        "#          'min_samples_split':[2,3,6,8],\n",
        "#          'min_samples_leaf':[1,2,3,4],\n",
        "#          'max_depth':[None,5,15,30]\n",
        "#          }\n",
        "\n",
        "# #the dimensionality is high, the number of combinations we have to search is enormous, using RandomizedSearchCV is a better option then GridSearchCV\n",
        "# grid = RandomizedSearchCV(estimator=rfr,param_distributions=params,verbose=True,cv=10)\n",
        "\n",
        "# #choosing 10 K-Folds makes sure i went through all of the data and didn't miss any pattern.\n",
        "# grid.fit(X_train, y_train)\n",
        "# grid.best_params_"
      ],
      "metadata": {
        "id": "pvJM0I3_o9L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build random forest model\n",
        "rdf_model = RandomForestRegressor( n_estimators=80)\n",
        "\n",
        "#Train model on training dataset\n",
        "rdf_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "tyZqqbqOkb81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict using model\n",
        "\n",
        "yl_pred = rdf_model.predict(X_train)\n",
        "\n",
        "#Calculate RMSE and MAPE\n",
        "\n",
        "print(\"The model performance for training dataset:\\n\")\n",
        "print(\"RMSPE :\",rmspe(y_train, yl_pred))\n",
        "print(\"MAPE :\",mape(y_train, yl_pred))"
      ],
      "metadata": {
        "id": "fEYQucbvoMWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict target on test data using model\n",
        "\n",
        "yl_pred_test = rdf_model.predict(X_test)\n",
        "\n",
        "#Calculate RMSE and MAPE\n",
        "\n",
        "print(\"The model performance for test dataset:\\n\")\n",
        "print(\"RMSPE :\",rmspe(y_test, yl_pred_test))\n",
        "print(\"MAPE :\",mape(y_test, yl_pred_test))"
      ],
      "metadata": {
        "id": "6QJqWqlcozs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score_2=rdf_model.score(X_train, y_train)\n",
        "test_score_2=rdf_model.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "vDRW30NYkeej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score_2,test_score_2"
      ],
      "metadata": {
        "id": "EaVxAxNqk-Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#storing 100 observations for analysis\n",
        "rf_prd = yl_pred_test[:100]\n",
        "rf_real = y_test[:100]\n",
        "dataset_rf = pd.DataFrame({'Real':rf_real,'PredictedRF':rf_prd})\n",
        "#storing absolute diffrences between actual sales price and predicted\n",
        "dataset_rf['diff']=(dataset_rf['Real']-dataset_rf['PredictedRF']).abs()"
      ],
      "metadata": {
        "id": "_YEic9bQplDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualising our predictions\n",
        "sns.lmplot(x='Real', y='PredictedRF', data=dataset_rf, line_kws={'color': 'red'},height=6, aspect=1);"
      ],
      "metadata": {
        "id": "VofNZPOSqdRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model 3 -  LARS Lasso Regression"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and train model.\n",
        "\n",
        "las = LassoLars(alpha=0.3)\n",
        "lasreg = las.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict using model\n",
        "yl_pred = lasreg.predict(X_train)\n",
        "#Calculate RMSE and MAPE\n",
        "\n",
        "print(\"The model performance for training dataset:\\n\")\n",
        "print(\"RMSPE :\",rmspe(y_train, yl_pred))\n",
        "print(\"MAPE :\",mape(y_train, yl_pred))"
      ],
      "metadata": {
        "id": "xYXvaDTSUZBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict target on test data using model\n",
        "\n",
        "yl_pred_test =lasreg.predict(X_test)\n",
        "\n",
        "#Calculate RMSE and MAPE\n",
        "\n",
        "print(\"The model performance for test dataset:\\n\")\n",
        "print(\"RMSPE :\",rmspe(y_test, yl_pred_test))\n",
        "print(\"MAPE :\",mape(y_test, yl_pred_test))"
      ],
      "metadata": {
        "id": "tkf1Ye86Va1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score_3=lasreg.score(X_train, y_train)\n",
        "test_score_3=lasreg.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "cMSrRKZ_kOMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score_3,test_score_3"
      ],
      "metadata": {
        "id": "UiXUgTsbkQPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#storing 100 observations for analysis\n",
        "las_prd = yl_pred_test[:100]\n",
        "las_real = y_test[:100]\n",
        "dataset_las = pd.DataFrame({'Real':las_real,'PredictedLas':las_prd})\n",
        "#storing absolute diffrences between actual sales price and predicted\n",
        "dataset_las['diff']=(dataset_las['Real']-dataset_las['PredictedLas']).abs()"
      ],
      "metadata": {
        "id": "VUNk40MKdLIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualising our predictions\n",
        "sns.lmplot(x='Real', y='PredictedLas', data=dataset_las, line_kws={'color': 'red'},height=6, aspect=1)"
      ],
      "metadata": {
        "id": "QPk-FnLhdidQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_df = pd.DataFrame({'Train_Score':[train_score_1,train_score_2,train_score_3],'Test_Score':[test_score_1,test_score_2,test_score_3]},index=['Linear Regression','Random Forest','Lasso Regression'])\n",
        "score_df"
      ],
      "metadata": {
        "id": "lIfwx0Z6l8XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest model is the accurate model as of now we can also improve the model performance by training the model with hyper parameter tunning."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"Model\": [\"Linear Regression\", \"Random Forest\", \"LARS Lasso Regression\"],\n",
        "    \"Training RMSPE\": [3.550758912267052, 0.06790501224557141, 4.9840958915470415],\n",
        "    \"Test RMSPE\": [1.1323232821970965, 0.16482888084789837, 1.238996213686942],\n",
        "    \"Training MAPE\": [14.529856129862303, 5.314279398689622, 14.528667832761268],\n",
        "    \"Test MAPE\": [14.529823278555165, 13.289990687719957, 14.528301424060732],\n",
        "}\n",
        "\n",
        "df1 = pd.DataFrame(data)\n",
        "df1"
      ],
      "metadata": {
        "id": "MbtVgOnnZHZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Summary:\n",
        "\n",
        "Random Forest: Exhibits the lowest errors on both the training and test sets, but shows signs of overfitting due to the large gap between training and test performance, particularly in MAPE.\n",
        "\n",
        "Linear Regression & LARS Lasso Regression: Both models exhibit similar performance with relatively high errors, but they show consistent behavior across training and test datasets. \n",
        "\n"
      ],
      "metadata": {
        "id": "iimBFnK0Zr2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}